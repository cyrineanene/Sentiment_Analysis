{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e04fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\cyrine.anene_amaris\\documents\\sentiment_analysis\\sentiment_analysis\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\cyrine.anene_amaris\\documents\\sentiment_analysis\\sentiment_analysis\\venv\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cyrine.anene_amaris\\documents\\sentiment_analysis\\sentiment_analysis\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\cyrine.anene_amaris\\documents\\sentiment_analysis\\sentiment_analysis\\venv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cyrine.anene_amaris\\documents\\sentiment_analysis\\sentiment_analysis\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyrine.anene_amaris\\documents\\sentiment_analysis\\sentiment_analysis\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b266d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d315b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources downloaded successfully.\n",
      "Dataset loaded: 50000 samples\n",
      "Raw dataset head:\n",
      "                                               review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "Raw label distribution in dataset:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n",
      "Unique raw sentiment values: ['positive' 'negative']\n",
      "Encoded labels mapping: {'negative': 0, 'positive': 1}\n",
      "Label distribution after encoding:\n",
      "sentiment_encoded\n",
      "1    25000\n",
      "0    25000\n",
      "Name: count, dtype: int64\n",
      "Corpus preprocessed: 50000 samples\n",
      "Vectorized data: (50000, 5000)\n",
      "Label distribution for training:\n",
      "sentiment_encoded\n",
      "1    25000\n",
      "0    25000\n",
      "Name: count, dtype: int64\n",
      "Train set: (40000, 5000), Test set: (10000, 5000)\n",
      "Train label distribution:\n",
      "sentiment_encoded\n",
      "0    20000\n",
      "1    20000\n",
      "Name: count, dtype: int64\n",
      "Test label distribution:\n",
      "sentiment_encoded\n",
      "1    5000\n",
      "0    5000\n",
      "Name: count, dtype: int64\n",
      "Model training completed.\n",
      "Model and vectorizer loaded successfully.\n",
      "Predicting on test data: (10000, 5000)\n",
      "Predictions made: (10000,)\n",
      "Prediction label distribution:\n",
      "1    5039\n",
      "0    4961\n",
      "Name: count, dtype: int64\n",
      "Prediction completed.\n",
      "F1 Score: 0.843510309791812\n",
      "Confusion Matrix:\n",
      " [[4195  805]\n",
      " [ 766 4234]]\n",
      "Accuracy: 0.8429\n",
      "Evaluation completed.\n",
      "\n",
      "Sample predictions:\n",
      "Sample 1: Predicted = negative, True = positive\n",
      "Sample 2: Predicted = negative, True = negative\n",
      "Sample 3: Predicted = negative, True = positive\n",
      "Sample 4: Predicted = positive, True = positive\n",
      "Sample 5: Predicted = positive, True = positive\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TextModel:\n",
    "    def __init__(self, max_features=5000):  # Increased max_features for better feature representation\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "        self.classifier = MultinomialNB()\n",
    "        \n",
    "    def train(self, X_train, y_train):\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        return self.classifier.predict(X_test)\n",
    "    \n",
    "    def save(self, vectorizer_path, model_path):\n",
    "        pickle.dump(self.vectorizer, open(vectorizer_path, 'wb'))\n",
    "        pickle.dump(self.classifier, open(model_path, 'wb'))\n",
    "    \n",
    "    def load(self, vectorizer_path, model_path):\n",
    "        self.vectorizer = pickle.load(open(vectorizer_path, 'rb'))\n",
    "        self.classifier = pickle.load(open(model_path, 'rb'))\n",
    "        return self.classifier, self.vectorizer\n",
    "    \n",
    "    def analyze_sentiment(self, sentence):\n",
    "        sentence_transformed = self.vectorizer.transform([sentence]).toarray()\n",
    "        result = self.classifier.predict(sentence_transformed)[0]\n",
    "        return 'Positive review' if result == 1 else 'Negative review'\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, y_true, y_pred):\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "    def calculate_metrics(self, labels=None):\n",
    "        self.f1 = f1_score(self.y_true, self.y_pred, average='binary', labels=labels, zero_division=0)\n",
    "        self.confusion_matrix = confusion_matrix(self.y_true, self.y_pred, labels=labels)\n",
    "        self.accuracy = accuracy_score(self.y_true, self.y_pred)\n",
    "        \n",
    "    def print_metrics(self):\n",
    "        print(\"F1 Score:\", self.f1)\n",
    "        print(\"Confusion Matrix:\\n\", self.confusion_matrix)\n",
    "        print(\"Accuracy:\", self.accuracy)\n",
    "\n",
    "def model_train(path):\n",
    "    try:\n",
    "        # Load dataset\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Dataset loaded: {len(df)} samples\")\n",
    "        print(\"Raw dataset head:\\n\", df.head())\n",
    "        print(\"Raw label distribution in dataset:\")\n",
    "        print(df['sentiment'].value_counts())\n",
    "\n",
    "        # Verify sentiment column values\n",
    "        print(\"Unique raw sentiment values:\", df['sentiment'].unique())\n",
    "\n",
    "        # Encode sentiment labels ('positive'/'negative' to 1/0)\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['sentiment_encoded'] = label_encoder.fit_transform(df['sentiment'])\n",
    "        print(\"Encoded labels mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "        print(\"Label distribution after encoding:\")\n",
    "        print(df['sentiment_encoded'].value_counts())\n",
    "\n",
    "        # Data preparation (assuming DataPreprocessor is defined elsewhere)\n",
    "        preprocessor = DataPreprocessor()\n",
    "        corpus = preprocessor.preprocess(df)\n",
    "        print(f\"Corpus preprocessed: {len(corpus)} samples\")\n",
    "\n",
    "        # Model NLP fitting\n",
    "        text_model = TextModel()\n",
    "        X = text_model.vectorizer.fit_transform(corpus).toarray()\n",
    "        y = df['sentiment_encoded']  # Use the encoded column\n",
    "        print(f\"Vectorized data: {X.shape}\")\n",
    "        print(\"Label distribution for training:\")\n",
    "        print(pd.Series(y).value_counts())\n",
    "\n",
    "        # Split data into training and test sets with stratification\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101, stratify=y)\n",
    "        print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "        print(\"Train label distribution:\")\n",
    "        print(pd.Series(y_train).value_counts())\n",
    "        print(\"Test label distribution:\")\n",
    "        print(pd.Series(y_test).value_counts())\n",
    "\n",
    "        # Train model\n",
    "        text_model.train(X_train, y_train)\n",
    "\n",
    "        # Save model and vectorizer\n",
    "        import os\n",
    "        os.makedirs(\"saved_model\", exist_ok=True)  # Ensure directory exists\n",
    "        text_model.save(\"saved_model/count-Vectorizer.pkl\", \"saved_model/Classification.pkl\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test, text_model, label_encoder\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in model_train: {e}\")\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "def model_predict(X_test, loaded_vector, loaded_model, label_encoder):\n",
    "    try:\n",
    "        # X_test is already vectorized, so use it directly for prediction\n",
    "        print(f\"Predicting on test data: {X_test.shape}\")\n",
    "        y_pred = loaded_model.predict(X_test)\n",
    "        print(f\"Predictions made: {y_pred.shape}\")\n",
    "        print(\"Prediction label distribution:\")\n",
    "        print(pd.Series(y_pred).value_counts())\n",
    "\n",
    "        # Decode predictions back to original labels ('positive'/'negative')\n",
    "        y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "        return y_pred, y_pred_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in model_predict: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Download NLTK stopwords\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)  # Added for tokenization\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK resources: {e}\")\n",
    "\n",
    "print(\"NLTK resources downloaded successfully.\")\n",
    "\n",
    "# Path to the IMDB dataset\n",
    "path = 'datasets/IMDB_Dataset.csv'\n",
    "\n",
    "# Train the model and get test data\n",
    "X_train, X_test, y_train, y_test, text_model, label_encoder = model_train(path)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "if X_train is not None:  \n",
    "    # Load the saved model and vectorizer for prediction\n",
    "    loaded_model, loaded_vector = text_model.load(\"saved_model/count-Vectorizer.pkl\", \"saved_model/Classification.pkl\")\n",
    "    print(\"Model and vectorizer loaded successfully.\")\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred, y_pred_labels = model_predict(X_test, loaded_vector, loaded_model, label_encoder)\n",
    "    print(\"Prediction completed.\")\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        # Evaluate predictions\n",
    "        eval = Evaluation(y_test, y_pred)\n",
    "        eval.calculate_metrics(labels=[0, 1])  # Explicitly include both classes\n",
    "        eval.print_metrics()\n",
    "        print(\"Evaluation completed.\")\n",
    "        \n",
    "        # Print sample predictions\n",
    "        print(\"\\nSample predictions:\")\n",
    "        for i in range(5):\n",
    "            print(f\"Sample {i+1}: Predicted = {y_pred_labels[i]}, True = {label_encoder.inverse_transform([y_test.iloc[i]])[0]}\")\n",
    "    else:\n",
    "        print(\"Prediction failed, cannot proceed with evaluation.\")\n",
    "else:\n",
    "    print(\"Training failed, cannot proceed with prediction and evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d351bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report dictionary: {'confusion_matrix': [[4195, 805], [766, 4234]], 'f1_score': 0.843510309791812, 'accuracy': 0.8429}\n"
     ]
    }
   ],
   "source": [
    "report_dict = {\n",
    "    \"confusion_matrix\": eval.confusion_matrix.tolist(), \n",
    "    \"f1_score\": eval.f1,\n",
    "    \"accuracy\": eval.accuracy\n",
    "}\n",
    "print(\"Report dictionary:\", report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddae47e",
   "metadata": {},
   "source": [
    "#### Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97aa995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/27 15:12:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/06/27 15:12:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run chill-sponge-452 at: http://127.0.0.1:5000/#/experiments/1/runs/bf7d66f01b2943cb9fb2b8d7fc1d8cac\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"Sentiment Analysis Experiment\")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"max_features\", 10000)\n",
    "    mlflow.log_param(\"ngram_range\", \"1-2\")\n",
    "    mlflow.log_param(\"classifier\", \"MultinomialNB\")\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'f1_score': report_dict['f1_score']\n",
    "    })\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(report_dict['confusion_matrix']))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "    mlflow.sklearn.log_model(text_model, \"MultinomialNB\") \n",
    "    # text_model.save(mlflow.active_run().info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569fe7f9",
   "metadata": {},
   "source": [
    "### Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02a74f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'MultinomialNB' already exists. Creating a new version of this model...\n",
      "2025/06/27 15:26:45 WARNING mlflow.tracking._model_registry.fluent: Run with id bf7d66f01b2943cb9fb2b8d7fc1d8cac has no artifacts at artifact path 'MultinomialNB', registering model based on models:/m-867be697efa747299014d4022c31cc75 instead\n",
      "2025/06/27 15:26:45 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MultinomialNB, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run chill-sponge-452 at: http://127.0.0.1:5000/#/experiments/1/runs/bf7d66f01b2943cb9fb2b8d7fc1d8cac\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'MultinomialNB'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'MultinomialNB'\n",
    "run_id='bf7d66f01b2943cb9fb2b8d7fc1d8cac'\n",
    "model_uri = f'runs:/{run_id}/{model_name}'\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbbcb68",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51fce318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data: (10000, 5000)\n",
      "Predictions made: (10000,)\n",
      "Prediction label distribution:\n",
      "1    5039\n",
      "0    4961\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "y_pred, y_pred_labels = model_predict(X_test, loaded_vector, loaded_model, label_encoder) #selon my use case\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a4310",
   "metadata": {},
   "source": [
    "### Transition the Model to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1883044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'anomaly-detection-prod'.\n",
      "Copied version '1' of model 'MultinomialNB' to version '1' of model 'anomaly-detection-prod'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1751034712421, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1751034712421, metrics=None, model_id=None, name='anomaly-detection-prod', params=None, run_id='bf7d66f01b2943cb9fb2b8d7fc1d8cac', run_link='', source='models:/MultinomialNB/1', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model_uri = f\"models:/{model_name}@challenger\"\n",
    "production_model_name = \"anomaly-detection-prod\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=current_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc1058",
   "metadata": {},
   "source": [
    "=> In docker container, we will be using this model using this code, see the documentation for more details.\n",
    "https://mlflow.org/docs/latest/ml/model-registry#model-registry-workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fea74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data: (10000, 5000)\n",
      "Predictions made: (10000,)\n",
      "Prediction label distribution:\n",
      "1    5039\n",
      "0    4961\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "prod_model_uri = f\"models:/{production_model_name}@champion\"\n",
    "\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "y_pred, y_pred_labels = model_predict(X_test, loaded_vector, loaded_model, label_encoder) #selon my use case\n",
    "y_pred[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
